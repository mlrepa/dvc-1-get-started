## üöÄ Tutorial: Data and Model Versioning with DVC

---

## üëÄ Description

* `üéì What is this?` This tutorial provides hands-on experience with **Data Version Control (DVC)**, demonstrating how to manage multiple datasets and machine learning model artifacts alongside your code. We'll use a classic image classification problem (cats vs. dogs) to illustrate DVC's capabilities for reproducibility and collaboration in MLOps.
* `üë©‚Äçüíª Who is this for?` ML Engineers, Data Scientists, and AI Developers who need to manage large datasets and models within Git repositories, ensuring experiment reproducibility and traceable deployments. A basic understanding of Python, Git, and command-line operations is assumed.
* `üéØ What will you learn?`
  * How to initialize a DVC project within a Git repository.
  * How to version large files and directories using `dvc add`.
  * How DVC tracks data changes using `.dvc` files and a cache.
  * How to switch between different versions of your data and models using `dvc checkout`.
  * How to set up and use remote storage to store and share DVC-tracked data with `dvc push` and `dvc pull`.
  * Advanced data access methods like `dvc get`, `dvc import`, and `dvc import-url`.
  * The fundamentals of DVC pipelines using `dvc stage add` and `dvc repro` for automating ML workflows.
* `üîç How is it structured?` We'll start by setting up our environment and performing basic file and directory versioning. Then, we'll demonstrate tracking changes and switching versions. Next, we'll configure remote storage for sharing data. Finally, we'll cover advanced data access patterns and introduce DVC pipelines for automated model versioning.
* `‚è±Ô∏è How much time will it take?` Approximately **55-70 minutes** to complete, providing a solid foundation in DVC for your MLOps workflows.

---

## üìñ Table of Contents

* [‚öôÔ∏è 1. Setting Up Your Environment](#-1-setting-up-your-environment)
  * [### Step 1.1: Prerequisites](#-step-11-prerequisites)
  * [### Step 1.2: Clone the Project Repository](#-step-12-clone-the-project-repository)
  * [### Step 1.3: Initialize Your Python Environment](#-step-13-initialize-your-python-environment)
  * [### Step 1.4: Initialize DVC in Your Project](#-step-14-initialize-dvc-in-your-project)
* [‚≠ê 2. Versioning Your First Dataset (File)](#-2-versioning-your-first-dataset-file)
  * [### Step 2.1: Download Raw Data](#-step-21-download-raw-data)
  * [### Step 2.2: Add the File to DVC](#-step-22-add-the-file-to-dvc)
  * [### Step 2.3: Commit DVC-file to Git](#-step-23-commit-dvc-file-to-git)
* [üìÅ 3. Versioning a Directory (Cats & Dogs Dataset)](#-3-versioning-a-directory-cats--dogs-dataset)
  * [### Step 3.1: Create a New Git Branch](#-step-31-create-a-new-git-branch)
  * [### Step 3.2: Download the Cats & Dogs Dataset](#-step-32-download-the-cats--dogs-dataset)
  * [### Step 3.3: Add the Directory to DVC](#-step-33-add-the-directory-to-dvc)
  * [### Step 3.4: Commit the DVC-file and Tag the Version](#-step-34-commit-the-dvc-file-and-tag-the-version)
* [‚ôªÔ∏è 4. Tracking Changes & Updating Data](#-4-tracking-changes--updating-data)
  * [### Step 4.1: Check Current DVC Status](#-step-41-check-current-dvc-status)
  * [### Step 4.2: Introduce a New Data Version](#-step-42-introduce-a-new-data-version)
  * [### Step 4.3: Capture the New Data Version with DVC](#-step-43-capture-the-new-data-version-with-dvc)
* [‚è™ 5. Switching Between Data Versions (`dvc checkout`)](#-5-switching-between-data-versions-dvc-checkout)
  * [### Step 5.1: Switch to a Different Branch (Without `datadir`)](#-step-51-switch-to-a-different-branch-without-datadir)
  * [### Step 5.2: Restore a Specific Data Version](#-step-52-restore-a-specific-data-version)
* [‚òÅÔ∏è 6. Storing and Sharing Data with Remotes](#-6-storing-and-sharing-data-with-remotes)
  * [### Step 6.1: Set Up a Local Remote Storage](#-step-61-set-up-a-local-remote-storage)
  * [### Step 6.2: Push Data to Remote Storage](#-step-62-push-data-to-remote-storage)
  * [### Step 6.3: Retrieve Data from Remote Storage](#-step-63-retrieve-data-from-remote-storage)
* [üì• 7. Advanced Data Access Commands](#-7-advanced-data-access-commands)
  * [### Step 7.1: Explore Remote DVC Repositories (`dvc list`)](#-step-71-explore-remote-dvc-repositories-dvc-list)
  * [### Step 7.2: Download Data Without Tracking (`dvc get`)](#-step-72-download-data-without-tracking-dvc-get)
  * [### Step 7.3: Download and Track Data (`dvc import`)](#-step-73-download-and-track-data-dvc-import)
  * [### Step 7.4: Track External URLs (`dvc import-url`)](#-step-74-track-external-urls-dvc-import-url)
* [ü§ñ 8. Automating Model Versioning with DVC Pipelines](#-8-automating-model-versioning-with-dvc-pipelines)
  * [### Step 8.1: Understand the `train.py` Script](#-step-81-understand-the-trainpy-script)
  * [### Step 8.2: Define an ML Pipeline Stage (`dvc stage add`)](#-step-82-define-an-ml-pipeline-stage-dvc-stage-add)
  * [### Step 8.3: Reproduce the Pipeline (`dvc repro`)](#-step-83-reproduce-the-pipeline-dvc-repro)
* [üîç 9. Understanding DVC File and Cache Internals](#-9-understanding-dvc-file-and-cache-internals)
  * [### Step 9.1: The `.dvc` File](#-step-91-the-dvc-file)
  * [### Step 9.2: The DVC Cache (`.dvc/cache`)](#-step-92-the-dvc-cache-dvc/cache)
  * [### Step 9.3: The `.dvc` Directory Structure](#-step-93-the-dvc-directory-structure)
* [üîó Additional Resources](#-additional-resources)
* [üéâ Conclusion & Next Steps](#-conclusion--next-steps)

---

## ‚öôÔ∏è 1. Setting Up Your Environment

Setup Instructions:

For detailed, step-by-step instructions on how to:

* Clone the project repository,
* Create a Python virtual environment using uv, and
* Install all required dependencies,

please refer to the üë©‚Äçüíª Quick Start: Installation & Setup section in the project's README.md file.

Once you have successfully completed the setup steps outlined in the README.md, your environment will be ready, and you can proceed with this tutorial.

### Step 1.4: Initialize DVC in Your Project

The first step in any DVC project is to initialize it within your Git repository.

```bash
dvc init
```

**Output:**

```
Initialized DVC repository.
You can now add your first data file or folder to DVC:
 dvc add <filename|dirname>

...
```

Let's see what DVC initialization has done:

```bash
ls -la .dvc/
```

**Output (example):**

```
total 8
drwxr-xr-x 4 user user 4096 Apr  1 10:00 .
drwxr-xr-x 8 user user 4096 Apr  1 10:00 ..
-rw-r--r-- 1 user user  122 Apr  1 10:00 config
drwxr-xr-x 2 user user 4096 Apr  1 10:00 tmp
-rw-r--r-- 1 user user    8 Apr  1 10:00 .gitignore
```

DVC creates a `.dvc/` directory and populates it with internal files. The most important one right now is `.dvc/config`, which stores DVC's settings. It also creates a `.dvc/.gitignore` file to ensure Git ignores DVC's internal cache.

Now, let's add these DVC-related files to Git and commit them. This ties your DVC setup to your Git repository.

```bash
git status
```

**Output (example):**

```
On branch tutorial
...
Untracked files:
  (use "git add <file>..." to include in what will be committed)
 .dvc/
```

```bash
git add .dvc/
git commit -m "Initialize DVC"
```

**Output:**

```
[tutorial 0c7d42a] Initialize DVC
 2 files changed, 5 insertions(+)
 create mode 100644 .dvc/.gitignore
 create mode 100644 .dvc/config
```

---

## ‚≠ê 2. Versioning Your First Dataset (File)

Now that DVC is set up, let's learn how to track individual files. We'll start with a simple XML dataset.

### Step 2.1: Download Raw Data

We'll download a small `data.xml` file. Notice the `-o data/data.xml` flag, which specifies the output path.

```bash
dvc get https://github.com/iterative/dataset-registry get-started/data.xml -o data/data.xml
```

**Output:**

```
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.72K/2.72K [00:00]
```

`dvc get` is like `wget` or `curl` but specifically designed to download files tracked by DVC (or Git) repositories.

### Step 2.2: Add the File to DVC

Now, let's tell DVC to track this `data.xml` file.

```bash
dvc add data/data.xml -v
```

**Output (example):**

```
Added 'data/data.xml' to DVC cache.
To share it, run 'dvc push'.
To put it under Git version control, run 'git add data/data.xml.dvc'.
```

What happened?

* DVC moved the actual `data.xml` file into its **cache** (located in `.dvc/cache`).
* It replaced the original `data.xml` with a small **`.dvc` file** (specifically, `data/data.xml.dvc`). This `.dvc` file is a plain text file that acts as a pointer to the data's content in the DVC cache.
* DVC also automatically created `data/.gitignore` to tell Git to ignore the actual `data.xml` content, only tracking the `.dvc` pointer file.

Let's inspect the `.dvc` file:

```bash
cat data/data.xml.dvc
```

**Output (example):**

```
outs:
- md5: a304afb96060aad90176268345e10355
  path: data.xml
  size: 2785
```

This `.dvc` file contains metadata about the data: an MD5 hash of its content, its path, and its size. The MD5 hash is crucial as it uniquely identifies the data's content in the DVC cache.

### Step 2.3: Commit DVC-file to Git

Since `data.xml.dvc` is just a small text file, we can commit it to Git. This links the specific version of your data to your Git commit history.

```bash
git add data/.gitignore data/data.xml.dvc
git commit -m "Add raw data.xml"
```

**Output:**

```
[tutorial 4d0e7f7] Add raw data.xml
 2 files changed, 6 insertions(+)
 create mode 100644 data/.gitignore
 create mode 100644 data/data.xml.dvc
```

Now, your Git repository tracks the *metadata* about your data, while DVC manages the large data content efficiently.

---

## üìÅ 3. Versioning a Directory (Cats & Dogs Dataset)

DVC excels at versioning entire directories containing many files, which is common for image datasets.

### Step 3.1: Create a New Git Branch

Let's create a new Git branch to track our first version of the cats and dogs dataset.

```bash
git checkout -b cats-dogs-v1
```

**Output:**

```
Switched to a new branch 'cats-dogs-v1'
```

### Step 3.2: Download the Cats & Dogs Dataset

We'll download a larger dataset consisting of cat and dog images into a directory named `datadir`. We're using `dvc get --rev` to specify a particular version of the dataset from the remote DVC repository.

```bash
dvc get --rev cats-dogs-v1 https://github.com/iterative/dataset-registry use-cases/cats-dogs -o datadir
```

**Output (example):**

```
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 67.5M/67.5M [00:03]
```

This command downloads the dataset, which includes `train` and `validation` subdirectories for cats and dogs images.

Let's confirm some files are there:

```bash
ls datadir/data/train/cats
```

**Output (example):**

```
cat.1.jpg  cat.10.jpg  cat.100.jpg ... cat.999.jpg
```

### Step 3.3: Add the Directory to DVC

Now, add the entire `datadir` to DVC.

```bash
dvc add datadir
```

**Output (example):**

```
Added 'datadir' to DVC cache.
To share it, run 'dvc push'.
To put it under Git version control, run 'git add datadir.dvc'.
```

Similar to adding a file, `dvc add` moves the `datadir` content to the DVC cache and creates `datadir.dvc`. For directories, DVC creates a special `.dir` file in its cache that lists the hashes of all files and subdirectories within the tracked directory. This allows efficient versioning of large folder structures.

Inspect the `.dvc` file for the directory:

```bash
cat datadir.dvc
```

**Output (example):**

```
outs:
- md5: b6923e1e4ad16ea1a7e2b328842d56a2.dir
  path: datadir
```

Notice the `.dir` suffix on the MD5 hash, indicating it refers to a directory hash.

### Step 3.4: Commit the DVC-file and Tag the Version

Commit the `datadir.dvc` file to Git and add a Git tag to mark this specific data version.

```bash
git add .gitignore datadir.dvc # .gitignore is created by DVC when adding a dir
git commit -m "Add cats-dogs dataset (v1)"
git tag -a cats-dogs-v1 -m "Dataset version v1.0"
```

**Output:**

```
[cats-dogs-v1 2a3b4c5] Add cats-dogs dataset (v1)
 2 files changed, 4 insertions(+)
 create mode 100644 .gitignore
 create mode 100644 datadir.dvc
```

You now have a Git tag `cats-dogs-v1` that points to a specific version of your `datadir` dataset!

---

## ‚ôªÔ∏è 4. Tracking Changes & Updating Data

One of DVC's core strengths is detecting and tracking changes to your data.

### Step 4.1: Check Current DVC Status

Use `dvc status` to see the state of your DVC-tracked files.

```bash
dvc status
```

**Output:**

```
Data and pipelines are up to date.
```

This indicates that all DVC-tracked data in your workspace matches what DVC expects (i.e., the content pointed to by the `.dvc` files in your current Git commit).

### Step 4.2: Introduce a New Data Version

Let's simulate an update where our `cats-dogs` dataset doubles in size (e.g., new images added after more data collection). We'll switch to a new Git branch first.

```bash
git checkout -b cats-dogs-v2
```

**Output:**

```
Switched to a new branch 'cats-dogs-v2'
```

Now, download the updated dataset version. This will overwrite the `datadir` in your workspace.

```bash
dvc get --rev cats-dogs-v2 https://github.com/iterative/dataset-registry use-cases/cats-dogs -o datadir
```

**Output (example):**

```
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90.7M/90.7M [00:04]
```

The `datadir` in your project now contains the "v2" version of the data.

Let's check `dvc status` again:

```bash
dvc status
```

**Output (example):**

```
? datadir
```

The `?` indicates that `datadir` exists in your workspace but is **not tracked by DVC's current `.dvc` file**. DVC recognizes that the content of `datadir` has changed since the last `dvc add` operation.

### Step 4.3: Capture the New Data Version with DVC

To capture this new version of the data, we simply run `dvc add` again.

```bash
dvc add datadir
```

**Output (example):**

```
M       datadir
Updated 'datadir' in DVC cache.
To share it, run 'dvc push'.
To put it under Git version control, run 'git add datadir.dvc'.
```

DVC detects the change, updates its cache, and modifies `datadir.dvc` to point to the new content hash.

Now, commit the updated `datadir.dvc` file to Git and tag it as `cats-dogs-v2`.

```bash
git add datadir.dvc
git commit -m "Updated cats-dogs dataset (v2)"
git tag -a cats-dogs-v2 -m "Dataset version v2.0"
```

**Output:**

```
[cats-dogs-v2 b7d8e9f] Updated cats-dogs dataset (v2)
 1 file changed, 2 insertions(+), 2 deletions(-)
```

You now have two distinct versions of your dataset (`cats-dogs-v1` and `cats-dogs-v2`) linked to different Git tags, all managed efficiently by DVC.

---

## ‚è™ 5. Switching Between Data Versions (`dvc checkout`)

The power of DVC comes from its ability to quickly switch between different versions of your data, just like Git switches code versions.

### Step 5.1: Switch to a Different Branch (Without `datadir`)

Let's switch back to our initial `tutorial` branch, which does *not* contain the `datadir.dvc` file.

```bash
git checkout tutorial
```

**Output:**

```
Switched to branch 'tutorial'
Your branch is up to date with 'origin/tutorial'.
```

Now, check your files:

```bash
ls
```

**Output (example):**

```
.dvc  .env  data  main.py  requirements.txt  train.py
```

Notice that `datadir` is gone from your workspace! This is because the `tutorial` branch doesn't have the `datadir.dvc` file in its Git history.

To restore the DVC-tracked data that *should* be present for the current Git commit, you need to run `dvc checkout`.

```bash
dvc checkout
```

**Output:**

```
M       data/data.xml
A       datadir
```

Wait, `datadir` suddenly appeared! That's because when you switched branches, `dvc checkout` detected that the `tutorial` branch's `data/data.xml.dvc` file points to a different version than what's currently in your workspace (it brought back the `data.xml` content) and also noticed `datadir` is not tracked there so it deleted it from your workspace to match the `tutorial` branch's Git state. This is an artifact of mixing different experiments on different branches.

Let's specifically try to restore the `cats-dogs-v1` version.

### Step 5.2: Restore a Specific Data Version

We want to get back the `cats-dogs-v1` dataset. First, switch your Git repository to that version's tag.

```bash
git checkout cats-dogs-v1
```

**Output:**

```
Note: switching to 'cats-dogs-v1'.
...
HEAD is now at 2a3b4c5... Add cats-dogs dataset (v1)
```

Now, if you check your files:

```bash
ls
```

**Output (example):**

```
.dvc  .env  data  datadir  main.py  requirements.txt  train.py
```

`datadir` is there, but its content is likely the `v2` content you just had. Why? Because `git checkout` only updates the `.dvc` *pointer files* in your workspace. It does *not* automatically fetch the actual data content. That's DVC's job!

To truly bring the `cats-dogs-v1` data content into your workspace, you must run `dvc checkout`:

```bash
dvc checkout
```

**Output:**

```
M       datadir
```

`M` indicates that `datadir` was modified (i.e., its content was swapped to the `v1` version). Now, your workspace's `datadir` should match the `cats-dogs-v1` content.

```bash
ls datadir/data/train/dogs | head -n 5
```

You can verify the number of files or file names to ensure you are on `v1` (e.g., v1 had 500 dogs, v2 had 1000). This demonstrates that DVC efficiently retrieves the correct data version from its cache without re-downloading or copying large files unnecessarily.

---

## ‚òÅÔ∏è 6. Storing and Sharing Data with Remotes

DVC's cache stores data locally. To share data with your team or deploy models, you need a **remote storage** location. This can be cloud storage (S3, GCS, Azure Blob), network file systems, or even a local directory.

### Step 6.1: Set Up a Local Remote Storage

For simplicity in this tutorial, we'll set up a local directory as our DVC remote. In a real-world scenario, this would be cloud storage.

```bash
mkdir -p /tmp/dvc_remote_storage
dvc remote add -d local_storage /tmp/dvc_remote_storage
```

**Output (example):**

```
Setting 'local_storage' as a default remote.
```

* **`mkdir -p /tmp/dvc_remote_storage`**: Creates a temporary directory.
    üëâ **IMPORTANT:** In a real project, **NEVER** use `/tmp` for long-term storage, as it's frequently cleared by your system. Use a persistent directory or, ideally, cloud storage.
* **`dvc remote add -d local_storage /tmp/dvc_remote_storage`**: Tells DVC about a new remote named `local_storage` and sets it as the default (`-d`).

This command modifies your `.dvc/config` file. Let's see:

```bash
cat .dvc/config
```

**Output (example):**

```
['core']
 remote = local_storage
['remote "local_storage"']
 url = /tmp/dvc_remote_storage
```

Now, commit this configuration change to Git so your team knows where the data is supposed to be stored.

```bash
git add .dvc/config
git commit -m "Add local DVC remote storage"
```

**Output:**

```
[cats-dogs-v1 8e9f0a1] Add local DVC remote storage
 1 file changed, 3 insertions(+)
```

### Step 6.2: Push Data to Remote Storage

To upload the DVC-tracked data from your local cache to the configured remote, use `dvc push`.

```bash
dvc push -v
```

**Output (example, showing data being pushed):**

```
Preparing to push data.
...
Pushing 'datadir' to 'local_storage'
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10/10 [00:00]
...
Pushed data to 'local_storage'.
```

DVC only pushes the actual data content, not the `.dvc` pointer files (which are in Git). It's intelligent enough to only upload data that isn't already present in the remote storage.

You can verify the data was pushed by checking the remote directory (it mirrors DVC's cache structure):

```bash
ls /tmp/dvc_remote_storage
```

**Output (example):**

```
a3 b6
```

These are directories named after the first two characters of the data's MD5 hashes.

### Step 6.3: Retrieve Data from Remote Storage

Now, let's simulate a scenario where a new team member joins or you're working on a new machine. The data isn't in your local DVC cache.

1. **Remove local cache and data:**

    ```bash
    rm -rf .dvc/cache
    rm -rf datadir
    rm -rf data/data.xml # Clean up the individual file too
    ```

    Your workspace should now be clean of the actual data files.

2. **Pull data from the remote:**

    ```bash
    dvc pull -v
    ```

    **Output (example):**

    ```
    Preparing to pull data.
    ...
    100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00]
    Pulled data to 'local_storage'.
    ```

    `dvc pull` checks the `.dvc` files in your current Git commit, looks up the corresponding data hashes in the remote, downloads them to your local DVC cache, and then links them back into your workspace.

    Verify that your data is back:

    ```bash
    ls datadir
    ls data
    ```

    You should see both `datadir` and `data/data.xml` restored. This demonstrates how DVC enables seamless data sharing and environment setup for collaborative ML projects.

---

## üì• 7. Advanced Data Access Commands

DVC offers more specialized commands for accessing and incorporating data from other DVC repositories or external URLs.

### Step 7.1: Explore Remote DVC Repositories (`dvc list`)

You can explore the contents of any DVC repository hosted on a Git server without cloning it first.

```bash
dvc list https://github.com/iterative/dataset-registry use-cases
```

**Output (example):**

```
cats-dogs/
get-started/
```

This shows the directories available under the `use-cases` path in that DVC dataset registry.

### Step 7.2: Download Data Without Tracking (`dvc get`)

You've already used `dvc get` earlier. It downloads data from a DVC remote repository to your current working directory, but it **does not** automatically add the downloaded data to *your* DVC project.

Let's get `cats-dogs` again, but this time, into a new folder to confirm it's not DVC-tracked locally:

```bash
dvc get https://github.com/iterative/dataset-registry use-cases/cats-dogs -o cats-dogs-untracked
```

**Output (example):**

```
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 90.7M/90.7M [00:04]
```

```bash
ls
```

You'll see `cats-dogs-untracked` directory. If you check `dvc status` or look for a `cats-dogs-untracked.dvc` file, you won't find one. This is useful when you just need a copy of data for temporary exploration or a one-off task.

### Step 7.3: Download and Track Data (`dvc import`)

`dvc import` is like `dvc get` followed by `dvc add`. It downloads data from another DVC repository *and* automatically registers it with your local DVC project, creating a `.dvc` file for it.

```bash
dvc import git@github.com:iterative/example-get-started data/data.xml -o imported_data.xml
```

**Output (example):**

```
Importing 'data/data.xml' from 'git@github.com:iterative/example-get-started'.
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.72K/2.72K [00:00]
```

Now, check your directory:

```bash
ls
cat imported_data.xml.dvc
```

You'll see `imported_data.xml` and its corresponding `imported_data.xml.dvc` file, indicating it's now tracked by your DVC project.

### Step 7.4: Track External URLs (`dvc import-url`)

`dvc import-url` allows you to track data directly from an external URL (HTTP/HTTPS, S3, GCS, HDFS, etc.) into your DVC project. It downloads the data and creates a `.dvc` file for it. This is useful for managing external datasets that you don't control.

```bash
dvc import-url https://data.dvc.org/get-started/data.xml -o external_data.xml
```

**Output (example):**

```
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2.72K/2.72K [00:00]
```

You will find `external_data.xml` and `external_data.xml.dvc` in your project. If the data at the URL changes, `dvc update external_data.xml.dvc` (or `dvc pull`) can pull the new version.

---

## ü§ñ 8. Automating Model Versioning with DVC Pipelines

While `dvc add` is great for raw data and final models, DVC also offers pipelines (`dvc stage add` and `dvc repro`) to version the *entire workflow* that produces a model, tying inputs, code, and outputs together. This is crucial for ML experiment reproducibility.

### Step 8.1: Understand the `train.py` Script

The `example-versioning` repository you cloned contains a `train.py` script. This script:

1. Loads data from the `datadir` (the cats & dogs dataset).
2. Performs a pre-processing step (feature extraction).
3. Trains a simple image classification model.
4. Saves the trained model as `model.weights.h5`.
5. Saves training metrics to `metrics.csv`.

For this tutorial, consider `train.py` as a "black box" ‚Äì the specific ML algorithm or Keras knowledge is not required. Our focus is on how DVC helps manage its inputs and outputs.

Let's ensure we're on a clean Git state, and remove any old `model.weights.h5.dvc` files if they exist from previous runs.

```bash
git checkout cats-dogs-v2 # Ensure we're on a branch with datadir
dvc checkout # Ensure datadir is present
dvc remove model.weights.h5.dvc --force 2>/dev/null || true # Ignore error if file doesn't exist
git rm --cached model.weights.h5.dvc 2>/dev/null || true # Remove from Git index if needed
```

This prepares our workspace for defining the pipeline.

### Step 8.2: Define an ML Pipeline Stage (`dvc stage add`)

Instead of manually adding `model.weights.h5` and `metrics.csv` after `train.py` runs, we can define a DVC pipeline stage that encapsulates the entire process.

```bash
dvc stage add -n train -d train.py -d datadir \
          -o model.weights.h5 -M metrics.csv \
          python train.py
```

**Output (example):**

```
'train' was added to your pipeline. To reproduce it, run 'dvc repro'.
```

What this command does:

* **`dvc stage add -n train`**: Creates a new pipeline stage named `train`.
* **`-d train.py -d datadir`**: Declares `train.py` (the code) and `datadir` (the input data) as **dependencies** of this stage. If either changes, DVC knows the stage needs to be re-run.
* **`-o model.weights.h5`**: Declares `model.weights.h5` as an **output** of this stage. DVC will version this file automatically.
* **`-M metrics.csv`**: Declares `metrics.csv` as a **metric file** output. This allows DVC to track and compare metrics across experiments.
* **`python train.py`**: Specifies the **command** that DVC should run to execute this stage.

This command also generates a `dvc.yaml` file (or updates it if it exists), which defines your ML pipeline.

```bash
cat dvc.yaml
```

**Output (example):**

```yaml
stages:
  train:
    cmd: python train.py
    deps:
    - train.py
    - datadir
    outs:
    - model.weights.h5
    metrics:
    - metrics.csv
```

This `dvc.yaml` file is plain text and versioned by Git, just like your code. It's the blueprint of your ML workflow.

Commit the `dvc.yaml` file to Git:

```bash
git add dvc.yaml
git commit -m "Define train pipeline stage"
```

**Output:**

```
[cats-dogs-v2 1f2g3h4] Define train pipeline stage
 1 file changed, 8 insertions(+)
 create mode 100644 dvc.yaml
```

### Step 8.3: Reproduce the Pipeline (`dvc repro`)

Now that the pipeline stage is defined, you can run it using `dvc repro`.

```bash
dvc repro
```

**Output (example):**

```
Running stage 'train':
    python train.py
... (output from train.py script, including Keras/TensorFlow logs) ...
100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00]
Reproduced stage 'train'.
```

`dvc repro` executes the `train` stage. It checks the dependencies (`train.py`, `datadir`). If any dependency has changed since the last run, it re-runs the command (`python train.py`) and captures the outputs (`model.weights.h5`, `metrics.csv`) into the DVC cache, updating their `.dvc` file pointers implicitly.

If you run `dvc repro` again without changing anything, it will report:

```bash
dvc repro
```

**Output:**

```
Data and pipelines are up to date.
```

This shows its ability to track and only re-run what's necessary, saving computation.

üëâ **Real-World MLOps Relevance:** Using `dvc stage add` and `dvc repro` for pipelines is a cornerstone of reproducible ML. It means that anyone (your future self, a teammate, a CI/CD system) can execute `dvc repro` and get the *exact same* data and model outputs, even if they only have the Git repository. This is critical for reliable deployments and debugging.

---

## üîç 9. Understanding DVC File and Cache Internals

Let's take a closer look at the files and directories DVC creates and manages, which underpin its versioning capabilities.

### Step 9.1: The `.dvc` File

We've already seen examples like `data/data.xml.dvc` and `datadir.dvc`. These are small YAML files that act as pointers to the actual data content, which lives in DVC's cache.

For a single file (`data/data.xml.dvc`), the `.dvc` file usually contains:

* `md5`: An MD5 hash of the file's content. This uniquely identifies the file.
* `path`: The relative path to the data file in the workspace.
* `size`: The size of the data file in bytes.

For a directory (`datadir.dvc`), the `md5` field will end with `.dir`, indicating that the hash represents the content of the entire directory, not a single file. This "directory hash" is calculated based on the hashes of all files and subdirectories within it.

### Step 9.2: The DVC Cache (`.dvc/cache`)

The `.dvc/cache` directory is where DVC stores the actual content of your data and model files.

```bash
ls -la .dvc/cache
```

**Output (example):**

```
drwxr-xr-x 4 user user 4096 Apr  1 10:00 .
drwxr-xr-x 8 user user 4096 Apr  1 10:00 ..
drwxr-xr-x 2 user user 4096 Apr  1 10:00 a3
drwxr-xr-x 2 user user 4096 Apr  1 10:00 b6
```

Inside `.dvc/cache`, DVC organizes files based on their MD5 hash. The first two characters of the hash form a subdirectory, and the rest become the filename within that subdirectory. This helps to prevent too many files in one directory and makes lookup efficient.

For example, if your `data.xml` had an MD5 hash starting with `a3`, its content would be stored in `.dvc/cache/a3/04afb96060aad90176268345e10355`. If `datadir` had a directory hash starting with `b6`, its metadata (listing hashes of its contents) would be in `.dvc/cache/b6/923e1e4ad16ea1a7e2b328842d56a2.dir`.

**Key Advantage:** If you have multiple DVC-tracked files with different names but *identical content*, DVC only stores one copy of that content in the cache, saving disk space.

### Step 9.3: The `.dvc` Directory Structure

The `.dvc/` directory is DVC's internal workspace for your project.

```bash
ls -la .dvc
```

**Output (example):**

```
drwxr-xr-x 9 user user 4096 Apr  1 10:00 .
drwxr-xr-x 8 user user 4096 Apr  1 10:00 ..
-rw-r--r-- 1 user user  122 Apr  1 10:00 config
drwxr-xr-x 2 user user 4096 Apr  1 10:00 cache
-rw-r--r-- 1 user user    8 Apr  1 10:00 .gitignore
drwxr-xr-x 2 user user 4096 Apr  1 10:00 tmp
# Other directories may appear depending on DVC version and features used:
# plots/, experiments/ etc.
```

* `.dvc/config`: Main DVC configuration (remotes, cache location, etc.).
* `.dvc/cache`: Where actual data/model content is stored.
* `.dvc/.gitignore`: Ensures Git ignores the cache and other DVC internal files.
* `.dvc/tmp`: Temporary files used by DVC.
* Other directories like `.dvc/plots` or `.dvc/experiments` might appear if you use DVC's plotting or experiment management features.

Understanding these internals helps you grasp how DVC efficiently links your Git-versioned code with your large, DVC-versioned data and models.

---

## üîó Additional Resources

* **DVC Official Documentation:** [https://dvc.org/doc](https://dvc.org/doc)
* **DVC Get Started:** [https://dvc.org/doc/start](https://dvc.org/doc/start)
* **DVC User Guide (Files & Directories):** [https://dvc.org/doc/user-guide/dvc-files-and-directories](https://dvc.org/doc/user-guide/dvc-files-and-directories)
* **DVC Get Started: Data Pipelines:** [https://dvc.org/doc/start/data-pipelines](https://dvc.org/doc/start/data-pipelines)
* **Example: Tracking a remote file (for `dvc import-url`):** [https://dvc.org/doc/command-reference/import-url](https://dvc.org/doc/command-reference/import-url)

---

## üéâ Conclusion & Next Steps

Congratulations! You've successfully completed this hands-on tutorial on Data and Model Versioning with DVC.

### Key Learnings

* You've learned how to initialize DVC and version large files and directories alongside your Git repository.
* You now understand the crucial role of `.dvc` files and the DVC cache in maintaining data integrity and reproducibility.
* You've mastered how to switch between different data versions and how to efficiently share data using DVC remotes.
* You've gained an initial understanding of DVC pipelines, which allow you to track and reproduce entire ML workflows.

### Where to go from here?

* **Experiment Management (MLflow):** Explore how DVC integrates seamlessly with MLflow for comprehensive experiment tracking, logging metrics, and managing models in a registry.
* **Continuous Integration/Delivery for ML (CI/CD for MLOps):** Learn how to set up CI/CD pipelines that leverage DVC's `dvc repro` to automate model retraining, evaluation, and deployment upon code or data changes.
* **Advanced DVC Features:** Dive deeper into DVC's capabilities for metrics and plots tracking, experiment versioning (`dvc exp`), and managing more complex data dependencies.
* **Cloud Remotes:** Transition from local DVC remotes to cloud storage solutions (AWS S3, Google Cloud Storage, Azure Blob Storage) for real-world production deployments.

Keep practicing these MLOps fundamentals. The ability to version, reproduce, and share your data and models reliably is a superpower in modern AI development!

[‚¨ÜÔ∏è Back to Table of Contents](#-table-of-contents)

---

## DVC Commands API Analysis and Suggestions for Updates

The provided tutorial uses a very solid set of DVC commands that are still highly relevant and foundational. DVC's CLI has remained remarkably stable in its core functionality, but there have been refinements, new features, and changes in recommended best practices, especially around pipeline management.

Here's an analysis of the commands used in the context of current DVC versions (e.g., 3.x and above, as of late 2023/early 2024):

### Commands Analyzed

* `dvc init`
* `dvc status`
* `dvc add`
* `dvc get`
* `dvc remote add`
* `dvc push`
* `dvc pull`
* `dvc list`
* `dvc import`
* `dvc import-url`
* `dvc remove`
* `dvc stage add` (formerly `dvc run`)
* `dvc repro`

### Analysis and Suggestions

1. **`dvc init`**:
    * **Current State:** Remains the same. It's the essential first step.
    * **Improvements/Tips:** None for the command itself. Emphasize committing `.dvc/` to Git immediately.

2. **`dvc status`**:
    * **Current State:** Works as described, showing discrepancies between workspace, cache, and `.dvc` files.
    * **Improvements/Tips:** Can be used with `--jobs N` for larger projects, though not typically necessary in a tutorial. No major API changes.

3. **`dvc add <path>`**:
    * **Current State:** Core command for data versioning. Behavior for files vs. directories is consistent.
    * **Improvements/Tips:**
        * The tutorial correctly introduces `dvc add` for `data.xml` and `datadir`. It's important to clarify that this is for *source data* or *external models* that you don't generate with a script *within* DVC.
        * For outputs of scripts (like `model.weights.h5` or `metrics.csv`), `dvc stage add` (or the older `dvc run`) is indeed the **preferred and recommended method** as it provides lineage. The tutorial's "Automating Capturing" section correctly pivots to this.

4. **`dvc get <repo_url> <path_in_repo> -o <output_path>`**:
    * **Current State:** Remains the command for downloading data from another DVC repository.
    * **Improvements/Tips:** None for the command itself. The `--rev` flag used in the tutorial is excellent for fetching specific versions, which is highly valuable.

5. **`dvc remote add [-d] <name> <url>`**:
    * **Current State:** Essential for configuring remotes.
    * **Improvements/Tips:**
        * The tutorial uses a local path `/tmp/dvc_remote_storage`. For a real-world scenario, explicitly mention cloud providers (S3, GCS, Azure Blob, Rucio, WebDAV etc.) as the common use cases for `url`. Example: `dvc remote add my_s3_remote s3://my-bucket/dvc-store`.
        * Briefly mention credential management for cloud remotes (e.g., DVC uses boto3 for AWS, google-cloud-storage for GCS, etc., relying on environment variables or config files).

6. **`dvc push [-v]`**:
    * **Current State:** Uploads cached data to the remote.
    * **Improvements/Tips:** No major changes. It's robust.

7. **`dvc pull [-v]`**:
    * **Current State:** Downloads missing data to the local cache and links it to the workspace.
    * **Improvements/Tips:** No major changes. It's robust.

8. **`dvc list <repo_url> [path]`**:
    * **Current State:** Useful for exploring DVC repositories remotely.
    * **Improvements/Tips:** None for the command itself.

9. **`dvc import <repo_url> <path_in_repo> -o <output_path>`**:
    * **Current State:** Imports data from another DVC repository and adds it to your project.
    * **Improvements/Tips:** None. It's a convenient shorthand for `dvc get` + `dvc add` for external DVC-tracked data.

10. **`dvc import-url <url> -o <output_path>`**:
    * **Current State:** Imports data from *any* URL (not necessarily a DVC repo) and tracks it.
    * **Improvements/Tips:** None. This is highly useful for integrating publicly available datasets or large external files directly into your DVC project.

11. **`dvc remove <dvc_file_path>`**:
    * **Current State:** Removes a `.dvc` file and its corresponding data from the workspace, optionally from the cache.
    * **Improvements/Tips:** The `--force` flag is often needed to delete the actual `.dvc` file from the workspace if it's already in the Git index. It's properly demonstrated for cleanup.

12. **`dvc stage add [-n <name>] -d <deps> -o <outs> [-M <metrics>] <command>`**:
    * **Current State:** This command is the **modern and highly recommended way** to define pipeline stages. It replaces the older `dvc run` command. The tutorial correctly uses `dvc stage add`.
    * **Improvements/Tips:**
        * The tutorial uses it perfectly to define dependencies and outputs.
        * Emphasize that this command creates/modifies `dvc.yaml`, the standard for DVC pipelines.
        * For metrics, `dvc metrics show` and `dvc metrics diff` can be powerful follow-up commands to demonstrate after defining a metric output. This is hinted at in the original "What's next?" section and could be briefly demonstrated.
        * Could mention `--live` flag for real-time metric tracking during training in more advanced scenarios (but out of scope for basic versioning).

13. **`dvc repro [stage_name]`**:
    * **Current State:** The core command to reproduce pipeline stages.
    * **Improvements/Tips:** No major changes. Crucial for reproducibility.

### Overall API Consistency and Evolution

DVC's command-line interface is generally very consistent and intuitive, often mirroring Git commands where applicable (`add`, `checkout`, `push`, `pull`). The evolution from `dvc run` to `dvc stage add` was a positive step, making the terminology clearer and better aligned with pipeline concepts (`dvc.yaml`).

The tutorial covers the essential commands comprehensively and explains their functionality well. No critical API syntax changes would render the tutorial commands obsolete. The proposed tutorial flow and explanations are highly effective for teaching DVC fundamentals.
